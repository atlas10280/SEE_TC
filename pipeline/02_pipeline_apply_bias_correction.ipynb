{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Dependencies\n",
    "##### define input directory\n",
    "nd2_path = \"/mnt/local/data2/Bootsma/2D_CTC/src/analysis/publication_code/test_data/\"\n",
    "\n",
    "##### define correction profile directory\n",
    "FF_path = \"/mnt/dho-nas06/zhaolab/long_term_storage/CTC/images/FF_profiles/\"\n",
    "\n",
    "##### Libraries\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "from skimage.restoration import rolling_ball\n",
    "\n",
    "\n",
    "sys.path.append('../src/') \n",
    "import SEE_TC as ctc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to extract a tile for a given region\n",
    "tile_size = 32 # Define the size of the tiles\n",
    "half_tile_size = tile_size // 2\n",
    "def extract_tile(region):\n",
    "        centroid = region.centroid\n",
    "        x, y = int(centroid[1]), int(centroid[0])\n",
    "\n",
    "        # Calculate start and end indices for slicing\n",
    "        start_x = x - half_tile_size\n",
    "        end_x = x + half_tile_size\n",
    "        start_y = y - half_tile_size\n",
    "        end_y = y + half_tile_size\n",
    "        \n",
    "        # Initialize a zero-padded tile\n",
    "        tile = np.zeros((tile_size, tile_size, image_array.shape[2]))\n",
    "        # tile_bin = np.zeros((tile_size, tile_size))\n",
    "\n",
    "        # Calculate valid ranges within the image\n",
    "        img_start_x = max(0, start_x)\n",
    "        img_end_x = min(image_array.shape[1], end_x)\n",
    "        img_start_y = max(0, start_y)\n",
    "        img_end_y = min(image_array.shape[0], end_y)\n",
    "\n",
    "        # Calculate valid ranges within the tile\n",
    "        tile_start_x = max(0, -start_x)\n",
    "        tile_end_x = tile_size - max(0, end_x - image_array.shape[1])\n",
    "        tile_start_y = max(0, -start_y)\n",
    "        tile_end_y = tile_size - max(0, end_y - image_array.shape[0])\n",
    "        \n",
    "        # Copy the valid region from the image to the tile\n",
    "        tile[tile_start_y:tile_end_y, tile_start_x:tile_end_x, :] = image_array[img_start_y:img_end_y, img_start_x:img_end_x, :]\n",
    "        return tile\n",
    "def extract_tile_bin(region):\n",
    "        centroid = region.centroid\n",
    "        x, y = int(centroid[1]), int(centroid[0])\n",
    "\n",
    "        # Calculate start and end indices for slicing\n",
    "        start_x = x - half_tile_size\n",
    "        end_x = x + half_tile_size\n",
    "        start_y = y - half_tile_size\n",
    "        end_y = y + half_tile_size\n",
    "        \n",
    "        # Initialize a zero-padded tile\n",
    "        # tile = np.zeros((tile_size, tile_size, image_array.shape[2]))\n",
    "        tile_bin = np.zeros((tile_size, tile_size))\n",
    "\n",
    "        # Calculate valid ranges within the image\n",
    "        img_start_x = max(0, start_x)\n",
    "        img_end_x = min(image_array.shape[1], end_x)\n",
    "        img_start_y = max(0, start_y)\n",
    "        img_end_y = min(image_array.shape[0], end_y)\n",
    "\n",
    "        # Calculate valid ranges within the tile\n",
    "        tile_start_x = max(0, -start_x)\n",
    "        tile_end_x = tile_size - max(0, end_x - image_array.shape[1])\n",
    "        tile_start_y = max(0, -start_y)\n",
    "        tile_end_y = tile_size - max(0, end_y - image_array.shape[0])\n",
    "        \n",
    "        # Copy the valid region from the image to the tile\n",
    "        tile_bin[tile_start_y:tile_end_y, tile_start_x:tile_end_x] = binary_array[img_start_y:img_end_y, img_start_x:img_end_x]\n",
    "        return tile_bin\n",
    "\n",
    "def tile_with_known_tiles(small_array, large_shape):\n",
    "    # Dimensions of the small array\n",
    "    h, w = small_array.shape\n",
    "    num_tiles_0 = math.ceil(large_shape[0]/small_array.shape[0])\n",
    "    num_tiles_1 = math.ceil(large_shape[1]/small_array.shape[1])\n",
    "    \n",
    "    # Compute the stride based on the number of tiles and the shape of the large array\n",
    "    stride_y = (large_shape[0] - h) // (num_tiles_0 - 1)\n",
    "    stride_x = (large_shape[1] - w) // (num_tiles_1 - 1)\n",
    "    \n",
    "    # Compute overlap based on stride and small array dimensions\n",
    "    overlap_y = h - stride_y\n",
    "    overlap_x = w - stride_x\n",
    "    \n",
    "    # Create arrays to store the sum of values and the counts of contributions\n",
    "    sum_array = np.zeros(large_shape)\n",
    "    count_array = np.zeros(large_shape)\n",
    "    \n",
    "    # Loop over each position where we place a tile\n",
    "    for i in range(num_tiles_0):\n",
    "        for j in range(num_tiles_1):\n",
    "            # Calculate the starting position of the tile\n",
    "            start_y = i * stride_y\n",
    "            start_x = j * stride_x\n",
    "            end_y = start_y + h\n",
    "            end_x = start_x + w\n",
    "            \n",
    "            # Place the tile in the sum_array and update the count_array\n",
    "            sum_array[start_y:end_y, start_x:end_x] += small_array\n",
    "            count_array[start_y:end_y, start_x:end_x] += 1\n",
    "\n",
    "    # Avoid division by zero by using np.maximum\n",
    "    avg_array = sum_array / np.maximum(count_array, 1)\n",
    "    \n",
    "    return avg_array\n",
    "\n",
    "def apply_FF_correction_impute(image, binary, channels, FF_path = FF_path):\n",
    "\n",
    "    print(\"FF correction using masks from: \"+FF_path)\n",
    "    print(image.shape, binary.shape, channels)\n",
    "    channels = [s if s == 'BF' else s[:3] for s in channels]\n",
    "    print(channels)\n",
    "    image = np.expand_dims(image,0)\n",
    "    dim_0 = image.shape[1] # define parameters for building mosaic to match size of input slide\n",
    "    dim_1 = image.shape[2]\n",
    "    large_shape = (dim_0, dim_1) \n",
    "    \n",
    "    binary = np.expand_dims(binary,0)\n",
    "    \n",
    "    img_fg, img_bg = ctc.split_foreground_background(image,binary)\n",
    "    image = image.squeeze()\n",
    "    img_fg = img_fg.squeeze()\n",
    "    img_bg = img_bg.squeeze()    \n",
    "    img_pp = np.zeros_like(image)\n",
    "\n",
    "    print(img_pp.shape, image.shape, img_fg.shape, img_bg.shape, binary.shape, channels)\n",
    "    for c in range(len(channels)):\n",
    "        print(\"c = \"+str(c))\n",
    "        print(\"image shape = \",image.shape)\n",
    "        ##### apply FF correction mask\n",
    "        channel_c = channels[c]\n",
    "        print(\"Processing \"+channel_c)\n",
    "        if channel_c == \"BF\": # no processing on brightfield\n",
    "            print(\"===========\")\n",
    "            print(\"BF\")\n",
    "            img_c = image[:,:,c] # capture raw channel       \n",
    "            img_pp[:,:,c] = img_c\n",
    "            print(img_pp.shape, image.shape)\n",
    "            print(\"===========\")\n",
    "        else: # handle all other channels\n",
    "######\n",
    "            from pathlib import Path\n",
    "            channel_c_prefix = [s[:1] for s in channel_c]   # safe for empty strings  \n",
    "            channel_c_prefix = channel_c_prefix[0]\n",
    "            \n",
    "            bg_pattern = \"FF_profile_BG_\"+channel_c_prefix+\"*\"\n",
    "            bg_path = list(Path(FF_path).glob(bg_pattern))\n",
    "            bg_path = [str(p) for p in bg_path][0]\n",
    "\n",
    "            fg_pattern = \"FF_profile_FG_\"+channel_c_prefix+\"*\"\n",
    "            fg_path = list(Path(FF_path).glob(fg_pattern))\n",
    "            fg_path = [str(p) for p in fg_path][0]  \n",
    "\n",
    "\n",
    "            ###########\n",
    "            if os.path.isfile(bg_path) == False | os.path.isfile(fg_path) == False:\n",
    "                print(\"skipping channel \"+channels[c]+\", no input\")\n",
    "                print(bg_path)\n",
    "                print(fg_path)\n",
    "                print(\"###############\\n\")                     \n",
    "                continue\n",
    "\n",
    "            FF_BG_norm = tifffile.imread(bg_path)\n",
    "            FF_BG_norm = tile_with_known_tiles(FF_BG_norm, large_shape)\n",
    "\n",
    "            FF_FG_norm = tifffile.imread(fg_path)\n",
    "            FF_FG_norm = tile_with_known_tiles(FF_FG_norm, large_shape)\n",
    "            \n",
    "            FF_FG_norm[FF_FG_norm == 0] = 1\n",
    "            img_c = image[:,:,c]\n",
    "            img_bg_c = img_bg[:,:,c]\n",
    "\n",
    "            avg_BG_est = np.nanmean(img_bg_c, axis=(0,1))\n",
    "            img_corrected = ((img_c-(avg_BG_est*FF_BG_norm))/FF_FG_norm)+avg_BG_est # apply formula from Kask et al.\n",
    "            img_corrected[img_corrected>65535]=65535 # clipping values that exceed uint16 range\n",
    "\n",
    "            # apply rolling ball                \n",
    "            # Make a dask array with chunks\n",
    "            img_dask = da.from_array(img_corrected, chunks=(5000, 5000))\n",
    "\n",
    "            # Apply rolling ball with overlap to avoid introducing tiling artifacts\n",
    "            bg = img_dask.map_overlap(\n",
    "                rolling_ball,\n",
    "                depth=21,           # Overlap 21 pixels on each side\n",
    "                boundary='reflect',\n",
    "                dtype=img_corrected.dtype,\n",
    "                radius=21           # Pass radius argument to rolling_ball\n",
    "            )\n",
    "            img_corrected = img_corrected - bg\n",
    "            #####\n",
    "            img_pp[:,:,c] = img_corrected\n",
    "    return(img_pp)\n",
    "\n",
    "# correct image, extract features, save both\n",
    "def correct_and_extract(file_i, target_scope = \"NA\", scope_specific = False, force_correction = True):    \n",
    "        bin_path_i = file_i+\".bin_open.tiff\"\n",
    "        img_path_i = file_i+\".nd2\"\n",
    "        meta_path_i = file_i+\".image_metadata.csv\"\n",
    "        meta_i = pd.read_csv(meta_path_i)\n",
    "        serial_i = meta_i['serial_number'].unique()\n",
    "        serial_i = str(serial_i[0])\n",
    "\n",
    "        FF_path_i = FF_path+serial_i+\"/\"\n",
    "        \n",
    "        run = True\n",
    "        if scope_specific == True:\n",
    "            scope_check = target_scope in FF_path_i\n",
    "            if scope_check:\n",
    "                run = True\n",
    "            else:\n",
    "                print(\"Skipping: \"+file_i)\n",
    "                run = False\n",
    "            \n",
    "        if run == True:\n",
    "\n",
    "            if os.path.isfile(img_path_i) == False:\n",
    "                print(\"skipping sample (\"+img_path_i+\") no image\")\n",
    "                print(\"###############\\n\")     \n",
    "            if os.path.isfile(bin_path_i) == False:\n",
    "                print(\"skipping sample (\"+bin_path_i+\") no binary\")\n",
    "                print(\"###############\\n\")                \n",
    "\n",
    "            if os.path.isfile(file_i+'.bias_corrected.tiff') == True:\n",
    "                print(\"skipping sample (\"+file_i+\") already processed\")\n",
    "                print(\"###############\\n\")     \n",
    "\n",
    "            else: # process if not already done, as checked above            \n",
    "                img_i, c_names = ctc.extract_all_array_nd2(img_path_i)\n",
    "                img_i = np.transpose(img_i, (1,2,0)) # channel last\n",
    "                print(\"Input image shape: \"+str(img_i.shape))\n",
    "                bin_i = tifffile.imread(file_i+\".bin_open.tiff\")            \n",
    "                print(\"Input binary shape: \"+str(bin_i.shape))            \n",
    "\n",
    "                ########### account for UNET padding\n",
    "                d0_bin = bin_i.shape[0]\n",
    "                d1_bin = bin_i.shape[1]\n",
    "                d0_img = img_i.shape[0]\n",
    "                d1_img = img_i.shape[1]\n",
    "                if d0_img != d0_bin and d1_img != d1_bin:\n",
    "                    print(\"CROPPING BIN TO FIT IMG\")\n",
    "                    bin_i = bin_i[0:d0_img,0:d1_img]\n",
    "\n",
    "                # get indices of each channel so they are arranged properly in output, adaptive for missing channels                \n",
    "                c3 = next((i for i, s in enumerate(c_names) if s.startswith(\"3\")), -1)\n",
    "                c4 = next((i for i, s in enumerate(c_names) if s.startswith(\"4\")), -1)\n",
    "                c5 = next((i for i, s in enumerate(c_names) if s.startswith(\"5\")), -1)\n",
    "                c6 = next((i for i, s in enumerate(c_names) if s.startswith(\"6\")), -1)\n",
    "                c7 = next((i for i, s in enumerate(c_names) if s.startswith(\"7\")), -1)\n",
    "                cB = next((i for i, s in enumerate(c_names) if s.startswith(\"B\")), -1)\n",
    "                \n",
    "                c_idx = [c3,c4,c5,c6,c7,cB]\n",
    "                c_idx = [x for x in c_idx if x != -1]\n",
    "                c_names_out = [c_names[i] for i in c_idx]\n",
    "                img_i = img_i[:,:,c_idx] # re-arrange channel order here\n",
    "\n",
    "                n_c = len(c_idx)\n",
    "                c_idx = np.append(c_idx,n_c)\n",
    "                \n",
    "                if force_correction == True:\n",
    "                    print(\"\\n=============applying FF correction...\\n=============\")\n",
    "                    img_pp = apply_FF_correction_impute(img_i, bin_i, c_names_out, FF_path=FF_path_i)\n",
    "                    \n",
    "                    # export image\n",
    "                    bin_i = np.expand_dims(bin_i,-1)\n",
    "                    img_pp = np.concatenate((img_pp,bin_i), axis = -1)\n",
    "                    img_pp = np.transpose(img_pp, (2,0,1)) # channel first\n",
    "                    print(\"Writing FF Corrected Image\")\n",
    "                    c_names_out = np.append(c_names_out, [\"UNET_open\"])\n",
    "                    tifffile.imwrite(file_i+\".bias_corrected.tiff\",\n",
    "                        data=img_pp,\n",
    "                        metadata={\n",
    "                            'axes':'CYX',\n",
    "                            'spacing':0.65,\n",
    "                            'orientation':'topleft',\n",
    "                            \"Channel\":{\"Name\":c_names_out.tolist()}},\n",
    "                        ome=True)\n",
    "                \n",
    "                else: # extract features, don't correct, use corrected image to extract\n",
    "                    print(\"FF correction exists, only extracting features\")\n",
    "                    binary = np.expand_dims(bin_i,0)\n",
    "                    binary = np.transpose(binary,(1,2,0))\n",
    "                    img_pp = tifffile.imread(file_i+\".bias_corrected.tiff\")\n",
    "                    img_pp = np.transpose(img_pp,(1,2,0))\n",
    "                    print(img_pp.shape)            \n",
    "                \n",
    "                return img_pp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### define input samples\n",
    "file_names = ctc.parse_nd2_paths(nd2_path, \".bin_open.tiff\", recursive=True)\n",
    "file_names = [s.replace(\".bin_open.tiff\", \"\") for s in file_names]\n",
    "print(f\"input: {len(file_names)} {file_names[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### correct instrument bias\n",
    "for file_i in file_names:\n",
    "    correct_and_extract(file_i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2D_CTC_pr1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
